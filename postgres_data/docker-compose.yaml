version: "3"
services:
  vllm-openai:
      container_name: vllm-openai
      deploy:
          resources:
              reservations:
                  devices:
                      - driver: nvidia
                        count: all
                        capabilities:
                            - gpu
      volumes:
          - ~/.cache/huggingface:/root/.cache/huggingface
          - ./models:/models
      environment:
          # - HUGGING_FACE_HUB_TOKEN=<hugging_face_token>
          - HUGGING_FACE_HUB_TOKEN=${HF_TOKEN}
          - TOKENIZERS_PARALLELISM=false
      ports:
          - 8000:8000
      ipc: host
      image: vllm/vllm-openai:latest
      # --max-model-len=${MAX_MODEL_LEN}
      command: --model ${LLM} --enforce-eager --quantization ${QUANT} --gpu-memory-utilization ${MEM_USAGE} --device cuda --download-dir /models

  postgres:
    build:
      # context: ./postgres
      dockerfile: postgres.Dockerfile
    ports:
      - "5432:5432"
    volumes:
      - ./data/:/var/lib/postgresql/data
      - ./postgres/vector_extension.sql:/docker-entrypoint-initdb.d/0-vector_extension.sql
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DB=vector
volumes:
  postgres_data: